{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtTc0u6I5qaq"
      },
      "outputs": [],
      "source": [
        "#Script to convert events2-.xlsx to a .txt with LOC and O tags\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Ensure stopwords are downloaded\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def extract_locations(location_data):\n",
        "    \"\"\"Extract location names from the JSON in the locations column.\"\"\"\n",
        "    locations = set()\n",
        "    try:\n",
        "        data_list = json.loads(f\"[{location_data}]\")  # Ensure JSON is parsed as a list\n",
        "        for entry in data_list:\n",
        "            if isinstance(entry, dict) and \"properties.name\" in entry:\n",
        "                locations.update(entry[\"properties.name\"])\n",
        "    except Exception:\n",
        "        pass\n",
        "    return locations\n",
        "\n",
        "def tag_text(text, locations):\n",
        "    \"\"\"Tag tokens in the text based on extracted locations, handling partial matches while ignoring stopwords.\"\"\"\n",
        "    words = text.split()\n",
        "    tagged_words = []\n",
        "\n",
        "    # Normalize location names to match variations in text\n",
        "    normalized_locs = {loc.lower(): loc for loc in locations}\n",
        "    location_tokens = set()\n",
        "    for loc in normalized_locs:\n",
        "        tokens = [token for token in loc.split() if token.lower() not in stop_words]  # Remove stopwords\n",
        "        location_tokens.update(tokens)\n",
        "\n",
        "    for word in words:\n",
        "        word_clean = re.sub(r'[^\\w]', '', word).lower()\n",
        "\n",
        "        # Check exact match or if any meaningful part of a location name matches\n",
        "        if word_clean in location_tokens or any(word_clean in loc.lower().split() and word_clean not in stop_words for loc in locations):\n",
        "            tagged_words.append(f\"{word} LOC\")\n",
        "        else:\n",
        "            tagged_words.append(f\"{word} O\")\n",
        "\n",
        "    return \"\\n\".join(tagged_words)\n",
        "\n",
        "def process_excel(file_path, output_txt):\n",
        "    df = pd.read_excel(file_path)\n",
        "    df[\"locations\"] = df[\"locations\"].astype(str)\n",
        "\n",
        "    with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "        for _, row in df.iterrows():\n",
        "            locations = extract_locations(row[\"locations\"])\n",
        "            tagged_text = tag_text(row[\"text\"], locations)\n",
        "            f.write(tagged_text + \"\\n\\n\")\n",
        "\n",
        "# # Example usage:\n",
        "# process_excel(\"events-2.xlsx\", \"output1.txt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
