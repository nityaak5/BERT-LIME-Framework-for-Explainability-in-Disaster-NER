{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219bf08e-9059-4d9b-8c31-7736a5dd6d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting jiwer\n",
      "  Downloading jiwer-3.0.4-py3-none-any.whl (21 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 KB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in ./env/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.10/site-packages (from transformers) (2.1.1)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 KB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.27\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 KB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 KB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapidfuzz<4,>=3\n",
      "  Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting click<9.0.0,>=8.1.3\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 KB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in ./env/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Collecting torch>=1.10.0\n",
      "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.4.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.0.0\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, mpmath, tzdata, tqdm, sympy, safetensors, regex, rapidfuzz, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, click, triton, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jiwer, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, accelerate\n",
      "Successfully installed accelerate-1.0.1 click-8.1.7 filelock-3.16.1 fsspec-2024.9.0 huggingface-hub-0.25.2 jiwer-3.0.4 mpmath-1.3.0 networkx-3.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 pandas-2.2.3 pytz-2024.2 rapidfuzz-3.10.0 regex-2024.9.11 safetensors-0.4.5 sympy-1.13.3 tokenizers-0.20.1 torch-2.4.1 tqdm-4.66.5 transformers-4.45.2 triton-3.0.0 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers jiwer pandas accelerate -U\n",
    "!pip install datasets tokenizers seqeval -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f84a41ad-d9f7-4d7c-9596-4532aaa52ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in ./env/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./env/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./env/lib/python3.10/site-packages (from ipywidgets) (8.27.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./env/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./env/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./env/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: stack-data in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: matplotlib-inline in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: exceptiongroup in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: decorator in ./env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./env/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./env/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./env/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./env/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import jiwer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "!pip install ipywidgets\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa8be28-366b-4fbd-b228-c47f6a129dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b92eeb-0e23-4d6d-8a1d-401bb9906c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def ingest_idrisi_data(data_dir):\n",
    "    sentences, labels = [], []\n",
    "\n",
    "    # Traverse each folder inside Train or Test\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "       \n",
    "        for file_name in files:  # For each file inside the current directory\n",
    "           \n",
    "            if file_name.endswith('.txt'):  # Process any .txt file\n",
    "                file_path = os.path.join(root, file_name)\n",
    "               \n",
    "                \n",
    "                with open(file_path, 'r') as f:\n",
    "                    current_sentence, current_labels = [], []\n",
    "                    for line in f:\n",
    "                        word_label = line.strip().split()\n",
    "                        if len(word_label) == 2:\n",
    "                            word, label = word_label\n",
    "                            current_sentence.append(word)\n",
    "                            current_labels.append(label)\n",
    "                        elif len(current_sentence) > 0:\n",
    "                            # Sentence boundary: Append sentence and its labels\n",
    "                            sentences.append(' '.join(current_sentence))\n",
    "                            labels.append(','.join(current_labels))\n",
    "                           \n",
    "                            current_sentence, current_labels = [], []\n",
    "                    if len(current_sentence) > 0:\n",
    "                        # Add the last sentence (if any) when file ends\n",
    "                        sentences.append(' '.join(current_sentence))\n",
    "                        labels.append(','.join(current_labels))\n",
    "                   \n",
    "\n",
    "    return pd.DataFrame({'sentence': sentences, 'word_labels': labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72aad772-325d-4a94-aa83-86771fe030e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= ingest_idrisi_data('Floods')\n",
    "\n",
    "test_california= ingest_idrisi_data('Test/california_wildfires_2018_loc_notok')\n",
    "test_idai= ingest_idrisi_data('Test/cyclone_idai_2019_loc_notok')\n",
    "test_pakistan= ingest_idrisi_data('Test/pakistan_earthquake_2019_loc_notok')\n",
    "test_dorian= ingest_idrisi_data('Test/hurricane_dorian_2019_loc_notok')\n",
    "test_midwestern= ingest_idrisi_data('Test/midwestern_us_floods_2019_loc_notok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a4c36e3-158e-4b3b-a0a5-0356be94dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_loc_labels(df):\n",
    "    # Modify the 'word_labels' column to replace B-LOC, I-LOC, L-LOC, and U-LOC with LOC\n",
    "    df['word_labels'] = df['word_labels'].apply(lambda x: re.sub(r'\\b[BILU]-LOC\\b', 'LOC', x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a1765c-0e16-470b-a5e9-fc6023413008",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= unify_loc_labels(train_df)\n",
    "\n",
    "test_california= unify_loc_labels(test_california)\n",
    "test_midwestern= unify_loc_labels(test_midwestern)\n",
    "test_pakistan= unify_loc_labels(test_pakistan)\n",
    "test_dorian= unify_loc_labels(test_dorian)\n",
    "test_idai= unify_loc_labels(test_idai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedcda20-45d6-48c4-b71f-222e1c878b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEVELOPING : Flash flooding , water rescues re...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># EllicottCityFlood happened once again , kill...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Searchers locate body of guardsman who went mi...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @TearsaSmith : Hero . Died trying to save a...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flags lowered to half - staff for Sgt . Eddiso...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,LOC,O,LOC,LOC,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>Kerala floods : Jalandhar Gurudwara to contrib...</td>\n",
       "      <td>LOC,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>RT @CAChirag : Should Central Govt Accept Fina...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>How Kerala ’s prisoners were cooking food for ...</td>\n",
       "      <td>O,LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>Centre clarifies : Rs 600 crore released so fa...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>Arranging SUBWAY JUNK FOOD for kerela flood vi...</td>\n",
       "      <td>O,O,O,O,O,LOC,O,O,O,O,O,LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1752 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     DEVELOPING : Flash flooding , water rescues re...   \n",
       "1     # EllicottCityFlood happened once again , kill...   \n",
       "2     Searchers locate body of guardsman who went mi...   \n",
       "3     RT @TearsaSmith : Hero . Died trying to save a...   \n",
       "4     Flags lowered to half - staff for Sgt . Eddiso...   \n",
       "...                                                 ...   \n",
       "1747  Kerala floods : Jalandhar Gurudwara to contrib...   \n",
       "1748  RT @CAChirag : Should Central Govt Accept Fina...   \n",
       "1749  How Kerala ’s prisoners were cooking food for ...   \n",
       "1750  Centre clarifies : Rs 600 crore released so fa...   \n",
       "1751  Arranging SUBWAY JUNK FOOD for kerela flood vi...   \n",
       "\n",
       "                                            word_labels  \n",
       "0     O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "1     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "2                   O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O  \n",
       "3                   O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "4     O,O,O,O,O,O,O,O,O,O,O,O,LOC,O,LOC,LOC,O,O,O,O,...  \n",
       "...                                                 ...  \n",
       "1747  LOC,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,O,...  \n",
       "1748        O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,LOC  \n",
       "1749  O,LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "1750  O,O,O,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,...  \n",
       "1751                        O,O,O,O,O,LOC,O,O,O,O,O,LOC  \n",
       "\n",
       "[1752 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dcff52-bdd7-49f9-bfab-7880962aa0a0",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92237884-d7b0-45bb-80fb-8d92b761c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any sentences have a mismatch in word and label count\n",
    "train_df['sentence_len'] = train_df['sentence'].apply(lambda x: len(x.split()))\n",
    "train_df['label_len'] = train_df['word_labels'].apply(lambda x: len(x.split(',')))\n",
    "\n",
    "# Identify mismatches\n",
    "mismatched = train_df[train_df['sentence_len'] != train_df['label_len']]\n",
    "if not mismatched.empty:\n",
    "    print(\"Mismatched entries found!\")\n",
    "    print(mismatched)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d0cffe-4944-4138-842e-6e53f8482ef6",
   "metadata": {},
   "source": [
    "\n",
    "Before fine-tuning, it’s essential to map the location mention labels from the BILOU format to a format that BERT can understand. This involves converting categorical labels (e.g., B-CITY,B-CNTY, B-CONT) into integer IDs, which the model will use during training. This mapping is critical because BERT outputs logits for each token, which are then converted back to these labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bc44622-d175-4e95-8aae-82f611363d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique tags from word labels\n",
    "tags = set(\",\".join(train_df.word_labels).split(','))\n",
    "\n",
    "# Create label to ID and ID to label mappings\n",
    "label2id = {k: v for v, k in enumerate(tags)}\n",
    "id2label = {v: k for v, k in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dceefd0-4950-4361-a229-758f49c384b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': 0, 'O': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09c649-b61d-4942-9839-16031c608c5f",
   "metadata": {},
   "source": [
    "# BERT works on wordpiece tokenization rather than word tokenization. This means that we should also define the labels at the wordpiece-level, rather than the word-level!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00f53f47-95db-4094-be65-4ad1f5aeecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2985242-0646-4e0e-a270-4c57dc5fa820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]  \n",
    "        word_labels = self.data.word_labels[index]  \n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        \n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        \n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "        \n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1171c1ef-a8e0-4e60-9c79-43219ea59fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 1\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9402299-3048-4f8e-8f86-4e2aa52ca45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = dataset(train_df, tokenizer, MAX_LEN)\n",
    "\n",
    "testset_california=  dataset(test_california, tokenizer, MAX_LEN)\n",
    "testset_idai= dataset(test_idai, tokenizer, MAX_LEN)\n",
    "testset_pakistan= dataset(test_pakistan, tokenizer, MAX_LEN)\n",
    "testset_dorian= dataset(test_dorian, tokenizer, MAX_LEN)\n",
    "testset_midwestern= dataset(test_midwestern, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d5bca0e-98d2-4527-b0cc-3ab8dc842371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch data loaders\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader= DataLoader(training_set, **train_params)\n",
    "\n",
    "testing_california= DataLoader(testset_california, **test_params)\n",
    "testing_idai= DataLoader(testset_idai, **test_params)\n",
    "testing_pakistan= DataLoader(testset_pakistan, **test_params)\n",
    "testing_dorian= DataLoader(testset_dorian, **test_params)\n",
    "testing_midwestern= DataLoader(testset_midwestern, **test_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34171911-3435-48f1-9d4b-851f0d589a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7895f20-0d37-4fc5-a5aa-5e2819fd8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2e6044f-1916-4471-89d9-70461da61726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "   \n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "        \n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "690a5aae-46e8-4dac-89fc-d4769b3b0f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 0.706308901309967\n",
      "Training loss per 100 training steps: 0.09073509408234812\n",
      "Training loss per 100 training steps: 0.055791513796256326\n",
      "Training loss per 100 training steps: 0.0438971798828311\n",
      "Training loss per 100 training steps: 0.036756457851507565\n",
      "Training loss epoch: 0.03545229639735745\n",
      "Training accuracy epoch: 0.9726331162865973\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b37087d3-cd62-4aa2-94c2-0ae2bf34caad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer_floods/tokenizer_config.json',\n",
       " 'tokenizer_floods/special_tokens_map.json',\n",
       " 'tokenizer_floods/vocab.txt',\n",
       " 'tokenizer_floods/added_tokens.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save_pretrained(\"ner_model_floods\")\n",
    "# tokenizer.save_pretrained(\"tokenizer_floods\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00f421e7-9f07-4dea-ad60-d603a855ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "# Load the saved model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"ner_model_floods\")\n",
    "model.to(device)\n",
    "\n",
    "# Load the saved tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tokenizer_floods\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29d65c6f-5d4b-48a9-9cd7-6146daa7c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'LOC',\n",
       "  'score': np.float32(0.56914014),\n",
       "  'word': 'rai',\n",
       "  'start': 23,\n",
       "  'end': 26}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# THIS IS HAPPENING BECAUSE PIPELINE IS ONLY FOR IOB FORMATS RIGHT NOW!!!!!\n",
    "\n",
    "nlp = pipeline(\"token-classification\",model=model.to(device),tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "example = (\"Floods detected in the Raipur district\")\n",
    "nlp(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8197a50-c5c7-43fa-87f6-8220872009b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def valid(model, testing_loader, tokenizer, id2label):\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps = 0\n",
    "    all_results = []  # To store results for each tweet\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            ids = batch['ids'].to(model.device)\n",
    "            mask = batch['mask'].to(model.device)\n",
    "            targets = batch['targets'].to(model.device)\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "            nb_eval_steps += 1\n",
    "            \n",
    "            # Print intermediate loss every 100 steps\n",
    "            if idx % 100 == 0:\n",
    "                loss_step = eval_loss / nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # Compute predictions and mask out special tokens\n",
    "            flattened_targets = targets.view(-1)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "            \n",
    "            active_accuracy = mask.view(-1) == 1\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            # Convert token IDs back to tokens\n",
    "            tokens = tokenizer.convert_ids_to_tokens(ids[0])  # For the first batch\n",
    "            \n",
    "            tweet_results = []\n",
    "            for i, (token, label, pred) in enumerate(zip(tokens, targets, predictions)):\n",
    "                label_str = id2label[label.item()]  # Get label string from label id\n",
    "                pred_str = id2label[pred.item()]  # Get prediction string from predicted id\n",
    "                \n",
    "                # Get probabilities for each token's predicted label (apply softmax)\n",
    "                token_probs = F.softmax(active_logits[i], dim=-1).cpu().numpy()  # Probabilities for the current token\n",
    "                token_pred_prob = token_probs[np.argmax(token_probs)]  # Probability for the predicted label\n",
    "                \n",
    "                tweet_results.append({\n",
    "                    'token': token,\n",
    "                    'label': label_str,\n",
    "                    'prediction': pred_str,\n",
    "                    'proba': token_pred_prob  # Include the predicted probability for this token\n",
    "                })\n",
    "            \n",
    "            # Add results for this tweet\n",
    "            all_results.append(tweet_results)\n",
    "            \n",
    "            # Update accuracy\n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    # Finalize average loss and accurac\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return all_results  # This will return a list of dictionaries for each tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23cc2123-0b3c-49bb-ba98-0ee5b8f0f8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.0030276982579380274\n",
      "Validation loss per 100 evaluation steps: 0.014879734196589504\n",
      "Validation loss per 100 evaluation steps: 0.014560579692954151\n",
      "Validation loss per 100 evaluation steps: 0.0136558204139753\n",
      "Validation loss per 100 evaluation steps: 0.013977698778978635\n",
      "Validation loss per 100 evaluation steps: 0.01315283681279487\n",
      "Validation loss per 100 evaluation steps: 0.013442409457735711\n",
      "Validation loss per 100 evaluation steps: 0.012936167004528175\n",
      "Validation loss per 100 evaluation steps: 0.01294258873935582\n",
      "Validation loss per 100 evaluation steps: 0.01299699240601358\n",
      "Validation loss per 100 evaluation steps: 0.01283958351988993\n",
      "Validation loss per 100 evaluation steps: 0.013048182332128639\n",
      "Validation Loss: 0.013006471563628118\n",
      "Validation Accuracy: 0.9872194066443639\n",
      "Validation loss per 100 evaluation steps: 0.016167152673006058\n",
      "Validation loss per 100 evaluation steps: 0.020457647925261224\n",
      "Validation loss per 100 evaluation steps: 0.02057685133849331\n",
      "Validation loss per 100 evaluation steps: 0.020330554537283274\n",
      "Validation loss per 100 evaluation steps: 0.02047049847360064\n",
      "Validation loss per 100 evaluation steps: 0.02111983410244949\n",
      "Validation loss per 100 evaluation steps: 0.021049951548345647\n",
      "Validation loss per 100 evaluation steps: 0.021042098911325004\n",
      "Validation loss per 100 evaluation steps: 0.021174202374105323\n",
      "Validation loss per 100 evaluation steps: 0.021152367635196453\n",
      "Validation loss per 100 evaluation steps: 0.020864488485573488\n",
      "Validation Loss: 0.021063509263554946\n",
      "Validation Accuracy: 0.9782726108255674\n",
      "Validation loss per 100 evaluation steps: 0.003369799582287669\n",
      "Validation loss per 100 evaluation steps: 0.03419895667933149\n",
      "Validation loss per 100 evaluation steps: 0.0384626810054355\n",
      "Validation loss per 100 evaluation steps: 0.039169699015510435\n",
      "Validation loss per 100 evaluation steps: 0.041871200881037914\n",
      "Validation loss per 100 evaluation steps: 0.04187160406106927\n",
      "Validation loss per 100 evaluation steps: 0.040444661245139756\n",
      "Validation Loss: 0.04058136305400978\n",
      "Validation Accuracy: 0.936518050263284\n",
      "Validation loss per 100 evaluation steps: 0.034295082092285156\n",
      "Validation loss per 100 evaluation steps: 0.01769903551505897\n",
      "Validation Loss: 0.016479025041021837\n",
      "Validation Accuracy: 0.9809975665752637\n",
      "Validation loss per 100 evaluation steps: 0.01424473337829113\n",
      "Validation loss per 100 evaluation steps: 0.016198722339041606\n",
      "Validation loss per 100 evaluation steps: 0.015710739066722382\n",
      "Validation loss per 100 evaluation steps: 0.015164625973276719\n",
      "Validation loss per 100 evaluation steps: 0.014654150064872053\n",
      "Validation loss per 100 evaluation steps: 0.014871464126014677\n",
      "Validation loss per 100 evaluation steps: 0.014953387117272123\n",
      "Validation loss per 100 evaluation steps: 0.015477946767292534\n",
      "Validation loss per 100 evaluation steps: 0.015591785089913919\n",
      "Validation Loss: 0.015510572623666289\n",
      "Validation Accuracy: 0.9811488735862075\n"
     ]
    }
   ],
   "source": [
    "#STEP 1: VALIDATION\n",
    "\n",
    "# all_results_california= valid(model, testing_california, tokenizer,id2label)\n",
    "# all_results_idai= valid(model, testing_idai, tokenizer,id2label)\n",
    "# all_results_pakistan= valid(model, testing_pakistan, tokenizer,id2label)\n",
    "# all_results_dorian= valid(model, testing_dorian, tokenizer,id2label)\n",
    "# all_results_midwestern= valid(model, testing_midwestern, tokenizer,id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90f2a7ab-82aa-4fb0-b4cb-5938607095ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def save_all_results(all_results, filename=None):\n",
    "    \"\"\"\n",
    "    Saves the all_results list to a pickle file with a custom filename.\n",
    "    \n",
    "    Parameters:\n",
    "        all_results (list): The list containing token, label, prediction, and proba for each token in each tweet.\n",
    "        filename (str, optional): The filename to save the pickle file. Default is None, which saves to 'all_results.pkl'.\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        filename = \"all_results.pkl\"\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    print(f\"All results saved to {filename}\")\n",
    "\n",
    "def load_all_results(filename=None):\n",
    "    \"\"\"\n",
    "    Loads the all_results list from a pickle file with a custom filename.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str, optional): The filename to load the pickle file from. Default is None, which loads from 'all_results.pkl'.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list containing token, label, prediction, and proba for each token in each tweet.\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        filename = \"all_results.pkl\"\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        all_results = pickle.load(f)\n",
    "    print(f\"All results loaded from {filename}\")\n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bd5115b-aa11-4204-bb21-cdd6efa35e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All results saved to all_results_california_flood.pkl\n",
      "All results saved to all_results_idai_flood.pkl\n",
      "All results saved to all_results_pakistan_flood.pkl\n",
      "All results saved to all_results_dorian_flood.pkl\n",
      "All results saved to all_results_midwestern_flood.pkl\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Saving these validation results\n",
    "# save_all_results(all_results_california, filename=\"all_results_california_flood.pkl\")\n",
    "# save_all_results(all_results_idai, filename=\"all_results_idai_flood.pkl\")\n",
    "# save_all_results(all_results_pakistan, filename=\"all_results_pakistan_flood.pkl\")\n",
    "# save_all_results(all_results_dorian, filename=\"all_results_dorian_flood.pkl\")\n",
    "# save_all_results(all_results_midwestern, filename=\"all_results_midwestern_flood.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "328fe7dd-b952-4350-bf10-92cd5f2735d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All results loaded from all_results_california_flood.pkl\n",
      "All results loaded from all_results_idai_flood.pkl\n",
      "All results loaded from all_results_pakistan_flood.pkl\n",
      "All results loaded from all_results_dorian_flood.pkl\n",
      "All results loaded from all_results_midwestern_flood.pkl\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Loading the validation result\n",
    "all_results_california=load_all_results(filename=\"all_results_california_flood.pkl\")\n",
    "all_results_idai = load_all_results(filename=\"all_results_idai_flood.pkl\")\n",
    "all_results_pakistan = load_all_results(filename=\"all_results_pakistan_flood.pkl\")\n",
    "all_results_dorian = load_all_results(filename=\"all_results_dorian_flood.pkl\")\n",
    "all_results_midwestern = load_all_results(filename=\"all_results_midwestern_flood.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e77f5bd9-f226-418b-8b3e-3bc2488c88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "def calculate_f1_and_report(results):\n",
    "    all_true_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for tweet_result in results:\n",
    "        for item in tweet_result:\n",
    "            token = item['token']\n",
    "            true_label = item['label']\n",
    "            pred_label = item['prediction']\n",
    "\n",
    "            # Exclude special tokens: [CLS], [SEP], and [PAD]\n",
    "            if token not in ['[CLS]', '[SEP]', '[PAD]']:  # Exclude special tokens\n",
    "                all_true_labels.append(true_label)\n",
    "                all_preds.append(pred_label)\n",
    "    \n",
    "    # Calculate F1 score for the labels\n",
    "    f1 = f1_score(all_true_labels, all_preds, average='micro')  # Use 'weighted' for multi-class tasks\n",
    "\n",
    "    # Print the classification report\n",
    "    report = classification_report(all_true_labels, all_preds)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21b7389b-6ee5-4a7a-b71e-ac4c7763e635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.87      0.76      0.81      1510\n",
      "           O       0.99      1.00      0.99     38639\n",
      "\n",
      "    accuracy                           0.99     40149\n",
      "   macro avg       0.93      0.88      0.90     40149\n",
      "weighted avg       0.99      0.99      0.99     40149\n",
      "\n",
      "0.9867493586390694\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.88      0.62      0.73      2210\n",
      "           O       0.98      1.00      0.99     45463\n",
      "\n",
      "    accuracy                           0.98     47673\n",
      "   macro avg       0.93      0.81      0.86     47673\n",
      "weighted avg       0.98      0.98      0.98     47673\n",
      "\n",
      "0.9784574077570113\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.89      0.41      0.56      2123\n",
      "           O       0.94      0.99      0.97     19658\n",
      "\n",
      "    accuracy                           0.94     21781\n",
      "   macro avg       0.92      0.70      0.77     21781\n",
      "weighted avg       0.94      0.94      0.93     21781\n",
      "\n",
      "0.9379275515357421\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.75      0.81      0.78       214\n",
      "           O       0.99      0.99      0.99      4968\n",
      "\n",
      "    accuracy                           0.98      5182\n",
      "   macro avg       0.87      0.90      0.88      5182\n",
      "weighted avg       0.98      0.98      0.98      5182\n",
      "\n",
      "0.9810883828637592\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.85      0.68      0.76      1426\n",
      "           O       0.99      0.99      0.99     32682\n",
      "\n",
      "    accuracy                           0.98     34108\n",
      "   macro avg       0.92      0.84      0.87     34108\n",
      "weighted avg       0.98      0.98      0.98     34108\n",
      "\n",
      "0.9816758531722763\n"
     ]
    }
   ],
   "source": [
    "#Step 4: F1 Score calculation\n",
    "results=[all_results_california, all_results_idai, all_results_pakistan, all_results_dorian, all_results_midwestern]\n",
    "for i in range(len(results)):\n",
    "    print(calculate_f1_and_report(results[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d2cc3-23ef-4e38-85cd-57aa4c11c105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
